# # services/ai_image_service.py
# import os
# import time
# import io
# import asyncio
# from typing import Optional, Tuple
# from concurrent.futures import ThreadPoolExecutor

# from PIL import Image
# from google import genai
# from google.genai import types

# from utils.logger import logger
# from config import settings

# # ThreadPoolExecutor for running blocking SDK calls without blocking the event loop
# _EXECUTOR = ThreadPoolExecutor(max_workers=2)


# class AIImageService:
#     """
#     Image generation service using Google Gemini (Nano Banana).
#     - Uses settings.GEMINI_API_KEY
#     - Uses model "gemini-2.5-flash-image" for image-to-image generation
#     - Runs blocking SDK calls in a threadpool so handlers remain async
#     - Returns (result_bytes | None, error_message | None, provider_name, processing_time_ms)
#     """

#     def __init__(self):
#         api_key = settings.GEMINI_API_KEY
#         if not api_key:
#             logger.error("[AIImageService] GEMINI_API_KEY is not set in settings")
#         # Create a genai client. The SDK will pick up credentials from environment if needed.
#         # If your SDK version supports passing api_key to Client, you can do: genai.Client(api_key=api_key)
#         try:
#             self._client = genai.Client()
#         except Exception:
#             # Fallback to configure if older SDK
#             genai.configure(api_key=api_key)
#             self._client = genai.Client()
#         # Use the flash image model by default
#         self._model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-image")

#     async def generate_image(self, image_bytes: bytes, prompt: str) -> Tuple[Optional[bytes], Optional[str], str, int]:
#         """
#         Perform image-to-image generation: send user's photo + prompt to Gemini and return generated bytes.
#         """
#         start_time = time.time()
#         provider = "gemini"
#         try:
#             logger.info("[AIImageService] generate_image start")
#             logger.debug(f"[AIImageService] prompt (head): {prompt[:200]}")

#             # Convert incoming bytes to a PIL Image for the SDK
#             try:
#                 input_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
#             except Exception as e:
#                 logger.exception("[AIImageService] failed to open input image")
#                 processing_time = int((time.time() - start_time) * 1000)
#                 return None, f"Invalid input image: {e}", "manual", processing_time

#             # Blocking SDK call wrapped for threadpool
#             def _call_gemini():
#                 logger.info(f"[AIImageService] calling Gemini model {self._model_name}")
#                 # Build config: request image-only response for clarity
#                 config = types.GenerateContentConfig(
#                     response_modalities=["IMAGE"],
#                     image_config=types.ImageConfig(
#                         # Keep default aspect ratio; callers can set env var or change here
#                         aspect_ratio="1:1",
#                         image_size="1K"
#                     ),
#                 )
#                 response = self._client.models.generate_content(
#                     model=self._model_name,
#                     contents=[prompt, input_image],
#                     config=config,
#                 )
#                 return response

#             loop = asyncio.get_running_loop()
#             response = await loop.run_in_executor(_EXECUTOR, _call_gemini)

#             # Parse response: iterate parts and extract first image part
#             result_bytes: Optional[bytes] = None
#             try:
#                 parts = getattr(response, "parts", None) or []
#                 for part in parts:
#                     # part.as_image() returns a PIL Image if present
#                     try:
#                         img = getattr(part, "as_image", None)
#                         if callable(img):
#                             pil_img = img()
#                         else:
#                             pil_img = None
#                     except Exception:
#                         pil_img = None

#                     if pil_img:
#                         buf = io.BytesIO()
#                         pil_img.save(buf, format="PNG")
#                         result_bytes = buf.getvalue()
#                         break

#                 # Some SDK versions expose inline_data on parts
#                 if result_bytes is None:
#                     for part in parts:
#                         inline = getattr(part, "inline_data", None)
#                         if inline and getattr(inline, "data", None):
#                             b64 = inline.data
#                             try:
#                                 import base64
#                                 result_bytes = base64.b64decode(b64)
#                                 break
#                             except Exception:
#                                 continue
#             except Exception as e:
#                 logger.exception("[AIImageService] error parsing Gemini response")
#                 result_bytes = None

#             processing_time = int((time.time() - start_time) * 1000)

#             if result_bytes:
#                 logger.info(f"[AIImageService] generation succeeded in {processing_time}ms")
#                 return result_bytes, None, provider, processing_time

#             logger.warning("[AIImageService] Gemini returned no usable image payload")
#             return None, "Gemini returned no image", provider, processing_time

#         except Exception as exc:
#             processing_time = int((time.time() - start_time) * 1000)
#             logger.exception(f"[AIImageService] generation error after {processing_time}ms: {exc}")
#             return None, str(exc), "manual", processing_time

#     async def download_telegram_file(self, bot, file_id: str) -> bytes:
#         """
#         Download a Telegram file (photo) and return raw bytes.
#         """
#         logger.info(f"[AIImageService] downloading telegram file {file_id}")
#         file = await bot.get_file(file_id)
#         file_bytes = await bot.download_file(file.file_path)
#         data = file_bytes.read()
#         logger.info(f"[AIImageService] downloaded {len(data)} bytes from Telegram")
#         return data


# services/ai_image_service.py
import time
import asyncio
from typing import Optional, Tuple

from utils.logger import logger


class AIImageService:
    """
    Stubbed Image generation service.
    - Does not call Google GenAI.
    - Simply waits 5 seconds and returns a failure result.
    - Returns (result_bytes | None, error_message | None, provider_name, processing_time_ms)
    """

    def __init__(self):
        # No external client setup needed
        self._model_name = "stubbed-model"

    async def generate_image(self, image_bytes: bytes, prompt: str) -> Tuple[Optional[bytes], Optional[str], str, int]:
        """
        Simulate image generation by waiting 5 seconds and returning failure.
        """
        start_time = time.time()
        provider = "stub"
        logger.info("[AIImageService] simulate generate_image start")
        logger.debug(f"[AIImageService] prompt (head): {prompt[:200]}")

        # Wait 5 seconds
        await asyncio.sleep(5)

        processing_time = int((time.time() - start_time) * 1000)
        logger.info(f"[AIImageService] simulated generation finished in {processing_time}ms")

        return None, "Image generation disabled (stubbed)", provider, processing_time

    async def download_telegram_file(self, bot, file_id: str) -> bytes:
        """
        Download a Telegram file (photo) and return raw bytes.
        """
        logger.info(f"[AIImageService] downloading telegram file {file_id}")
        file = await bot.get_file(file_id)
        file_bytes = await bot.download_file(file.file_path)
        data = file_bytes.read()
        logger.info(f"[AIImageService] downloaded {len(data)} bytes from Telegram")
        return data
